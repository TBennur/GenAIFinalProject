{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkjGY02qRY12"
      },
      "source": [
        "# Setup\n",
        "This section initializes the dataset creation packages and import modules. First, we download the necessary packages and modules - we require PyAVm, PyTorch (and Pytorch Lightning), Youtube DL and FFMPEG. We then create folders and configure our crawler parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_efhjhDhIDH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uary6-tQkD2X"
      },
      "outputs": [],
      "source": [
        "# Installs\n",
        "!pip install av\n",
        "!pip install --upgrade youtube_dl\n",
        "!pip install --upgrade pytorch_lightning\n",
        "!apt -y install ffmpeg lame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V55XLhpRtxE"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import requests\n",
        "import os\n",
        "\n",
        "import os.path as osp\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "import glob\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.video_utils import VideoClips\n",
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37KX_ouucx7-"
      },
      "outputs": [],
      "source": [
        "# Setup Dataset\n",
        "os.makedirs(\"video_dataset\")\n",
        "os.makedirs(\"video_dataset/trainTANAY\")\n",
        "os.makedirs(\"video_dataset/testTANAY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srVw0ZAhoN7-"
      },
      "outputs": [],
      "source": [
        "# CONFIG\n",
        "# Tanay is 1400 - 3000\n",
        "# Nithya is 3000 - 4800 (Start at 30)\n",
        "# Cathleen is 4800 - END (Roughly 6300) (Start at 48)\n",
        "KEEP_PROB = 0.2\n",
        "# Increment every time\n",
        "OVERALL_CHUNK_TRAIN = 15\n",
        "OVERALL_CHUNK_TEST = 14\n",
        "# Increase by between 100 and 250\n",
        "START_TRAIN = 2000\n",
        "START_TEST = 2200\n",
        "END_TEST = 2250 # 80% Train, 20% Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pBUq9FjslY3"
      },
      "source": [
        "# Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0dozHcXSQUE"
      },
      "outputs": [],
      "source": [
        "# Fetch video list\n",
        "video_list_url = \"https://data.csail.mit.edu/tofu/dataset/original_video_list.txt\"\n",
        "r = requests.get(video_list_url, auth=('user', 'pass'))\n",
        "full_video_list = r.text.split()\n",
        "\n",
        "def splits(video_list):\n",
        "  train_list = video_list[START_TRAIN:START_TEST]\n",
        "  test_list = video_list[START_TEST:END_TEST]\n",
        "  return train_list, test_list\n",
        "\n",
        "# Test and train splits\n",
        "train_list, test_list = splits(full_video_list)\n",
        "\n",
        "print(len(full_video_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiqPqKmalSG0"
      },
      "outputs": [],
      "source": [
        "# download train videos\n",
        "for ind,url in enumerate(train_list):\n",
        "  !youtube-dl $url -f 'bestvideo[height<=480]' -o 'video_dataset/trainTANAY/%(title)s.mp4' -q\n",
        "\n",
        "# download test videos\n",
        "for ind,url in enumerate(test_list):\n",
        "  !youtube-dl $url -f 'bestvideo[height<=480]' -o 'video_dataset/testTANAY/%(title)s.mp4' -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcAt7G2MmUnQ"
      },
      "outputs": [],
      "source": [
        "# Copied directly from https://github.com/wilson1yan/VideoGPT\n",
        "def preprocess(video, resolution, sequence_length=None):\n",
        "    # video: THWC, {0, ..., 255}\n",
        "    video = video.permute(0, 3, 1, 2).float() / 255. # TCHW\n",
        "    t, c, h, w = video.shape\n",
        "\n",
        "    scale = resolution / min(h, w)\n",
        "    if h < w:\n",
        "        target_size = (resolution, math.ceil(w * scale))\n",
        "    else:\n",
        "        target_size = (math.ceil(h * scale), resolution)\n",
        "    video = F.interpolate(video, size=target_size, mode='bilinear',\n",
        "                          align_corners=False)\n",
        "\n",
        "    # center crop\n",
        "    t, c, h, w = video.shape\n",
        "    w_start = (w - resolution) // 2\n",
        "    h_start = (h - resolution) // 2\n",
        "    video = video[:, :, h_start:h_start + resolution, w_start:w_start + resolution]\n",
        "    video = video.permute(1, 0, 2, 3).contiguous() # CTHW\n",
        "\n",
        "    video -= 0.5\n",
        "\n",
        "    return video\n",
        "\n",
        "# Custom dataset class\n",
        "class VideoDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, data_folder, sequence_length, resolution=64):\n",
        "\n",
        "        super().__init__()\n",
        "        self.sequence_length = sequence_length\n",
        "        self.resolution = resolution\n",
        "        folder = osp.join(data_folder, 'trainTANAY')\n",
        "        files = glob.glob(osp.join(folder, '**', f'*.mp4'), recursive=True)\n",
        "\n",
        "        print(f\"Found {len(files)} files\")\n",
        "\n",
        "        warnings.filterwarnings('ignore')\n",
        "        clips = VideoClips(files, clip_length_in_frames=sequence_length, frames_between_clips=sequence_length, num_workers=1)\n",
        "        print(\"files converted\")\n",
        "\n",
        "        self.clips = []\n",
        "\n",
        "        for i in range(clips.num_clips()):\n",
        "          # Sample with probability\n",
        "          if random.random() > KEEP_PROB:\n",
        "            continue\n",
        "          try:\n",
        "            video, _, _, idx = clips.get_clip(i)\n",
        "            self.clips.append(preprocess(video, resolution))\n",
        "          except:\n",
        "            continue\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clips)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.clips[idx], self.clips[idx][:, ::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHob9UxywkHW"
      },
      "outputs": [],
      "source": [
        "train_dataset = VideoDataset('./video_dataset', 31, resolution=64)\n",
        "print((train_dataset[0][0].shape, train_dataset[0][1].shape), len(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmmtLIfvLK6n"
      },
      "outputs": [],
      "source": [
        "# Copied directly from https://github.com/wilson1yan/VideoGPT\n",
        "def preprocess(video, resolution, sequence_length=None):\n",
        "    # video: THWC, {0, ..., 255}\n",
        "    video = video.permute(0, 3, 1, 2).float() / 255. # TCHW\n",
        "    t, c, h, w = video.shape\n",
        "\n",
        "    scale = resolution / min(h, w)\n",
        "    if h < w:\n",
        "        target_size = (resolution, math.ceil(w * scale))\n",
        "    else:\n",
        "        target_size = (math.ceil(h * scale), resolution)\n",
        "    video = F.interpolate(video, size=target_size, mode='bilinear',\n",
        "                          align_corners=False)\n",
        "\n",
        "    # center crop\n",
        "    t, c, h, w = video.shape\n",
        "    w_start = (w - resolution) // 2\n",
        "    h_start = (h - resolution) // 2\n",
        "    video = video[:, :, h_start:h_start + resolution, w_start:w_start + resolution]\n",
        "    video = video.permute(1, 0, 2, 3).contiguous() # CTHW\n",
        "\n",
        "    video -= 0.5\n",
        "\n",
        "    return video\n",
        "\n",
        "# Custom dataset class\n",
        "class VideoDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, data_folder, sequence_length, resolution=64):\n",
        "\n",
        "        super().__init__()\n",
        "        self.sequence_length = sequence_length\n",
        "        self.resolution = resolution\n",
        "        folder = osp.join(data_folder, 'testTANAY')\n",
        "        files = glob.glob(osp.join(folder, '**', f'*.mp4'), recursive=True)\n",
        "\n",
        "        print(f\"Found {len(files)} files\")\n",
        "\n",
        "        warnings.filterwarnings('ignore')\n",
        "        clips = VideoClips(files, clip_length_in_frames=sequence_length, frames_between_clips=sequence_length, num_workers=1)\n",
        "        print(\"files converted\")\n",
        "\n",
        "        self.clips = []\n",
        "\n",
        "        for i in range(clips.num_clips()):\n",
        "          # Sample with probability\n",
        "          if random.random() > KEEP_PROB:\n",
        "            continue\n",
        "          try:\n",
        "            video, _, _, idx = clips.get_clip(i)\n",
        "            self.clips.append(preprocess(video, resolution))\n",
        "          except:\n",
        "            continue\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.clips)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.clips[idx], self.clips[idx][:, ::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xYecIk-CvmPG"
      },
      "outputs": [],
      "source": [
        "test_dataset = VideoDataset('./video_dataset', 31, resolution=64)\n",
        "print((test_dataset[0][0].shape, test_dataset[0][1].shape), len(test_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BGcqENTZrOG"
      },
      "source": [
        "# Saving and Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "my707jneNFB_"
      },
      "outputs": [],
      "source": [
        "# Save to disk\n",
        "train_file = f'train_dataset_part{OVERALL_CHUNK_TRAIN}.pt'\n",
        "test_file = f'test_dataset_part{OVERALL_CHUNK_TEST}.pt'\n",
        "torch.save(torch.stack(train_dataset.clips).to(torch.float16), train_file)\n",
        "torch.save(torch.stack(test_dataset.clips).to(torch.float16), test_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qv8mZrtgN0jQ"
      },
      "outputs": [],
      "source": [
        "train_loc = f'/content/drive/MyDrive/GenAIFinalProject/Data/Train/{train_file}'\n",
        "test_loc = f'/content/drive/MyDrive/GenAIFinalProject/Data/Test/{test_file}'\n",
        "\n",
        "!mv $train_file $train_loc\n",
        "!mv $test_file $test_loc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZZYT6fLno1Qm"
      },
      "outputs": [],
      "source": [
        "!rm -rf video_dataset"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}